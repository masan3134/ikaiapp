const axios = require('axios');
const mammoth = require('mammoth');
const geminiRateLimiter = require('../utils/geminiRateLimiter');

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
if (!GEMINI_API_KEY) {
  throw new Error('GEMINI_API_KEY ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ!');
}

// Google'Ä±n Ã¶nerdiÄŸi gÃ¼ncel ve stabil Flash modeli
const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent';

/**
 * BATCH SIZE CONFIGURATION
 *
 * Calculation (Gemini 2.0 Flash):
 * - maxOutputTokens: 8192
 * - Safety margin: 20%
 * - Tokens per CV: ~1000 (average JSON output)
 * - Formula: (8192 * 0.8) / 1000 = 6.5
 *
 * BATCH_SIZE = 6 (safe limit for token constraints)
 *
 * Examples:
 * - 25 CVs â†’ 5 batches (6+6+6+6+1)
 * - 50 CVs â†’ 9 batches (6+6+6+6+6+6+6+6+2)
 */
const BATCH_SIZE = 6;

/**
 * Delay between batches (milliseconds)
 * Prevents rate limiting
 */
const BATCH_DELAY_MS = 2000;

/**
 * Birden fazla CV'yi tek bir Gemini API Ã§aÄŸrÄ±sÄ±yla toplu olarak analiz eder.
 * Bu yÃ¶ntem, tek tek Ã§aÄŸrÄ±lara gÃ¶re daha hÄ±zlÄ± ve maliyet etkindir.
 *
 * @param {string} analysisId - Analiz iÅŸleminin kimliÄŸi (loglama iÃ§in).
 * @param {object} jobPosting - Ä°ÅŸ ilanÄ± detaylarÄ±: {title, department, details, notes}.
 * @param {Array<object>} candidatesData - Aday verileri dizisi: [{id, cvBuffer, fileName}].
 * @returns {Promise<Array<object>>} TÃ¼m adaylar iÃ§in analiz sonuÃ§larÄ±nÄ± iÃ§eren bir Promise.
 */
async function batchAnalyzeCVs(analysisId, jobPosting, candidatesData) {
  try {
    console.log(`ğŸš€ Gemini Direct Batch: ${candidatesData.length} CVs in 1 API call`);

    // Build the master prompt
    const systemPrompt = buildBatchPrompt(jobPosting, candidatesData.length);

    // Prepare multi-part request with all CV files
    const parts = [
      { text: systemPrompt }
    ];

    // Add each CV as inline data (format-aware: PDF/DOCX/TXT)
    for (let i = 0; i < candidatesData.length; i++) {
      const candidate = candidatesData[i];
      const fileExt = candidate.fileName.toLowerCase().split('.').pop();

      // CV header
      parts.push({
        text: `\n\n--- CV ${i + 1} (Candidate ID: ${candidate.id}, Format: ${fileExt.toUpperCase()}) ---\n`
      });

      // Format-specific processing
      if (fileExt === 'txt') {
        // TXT: Direct text (fastest & most reliable)
        const cvText = candidate.cvBuffer.toString('utf-8');
        parts.push({
          text: cvText
        });
        console.log(`  ğŸ“„ CV ${i + 1}: TXT (${cvText.length} chars)`);

      } else if (fileExt === 'docx') {
        // DOCX: Extract text using mammoth
        try {
          const result = await mammoth.extractRawText({ buffer: candidate.cvBuffer });
          parts.push({
            text: result.value
          });
          console.log(`  ğŸ“„ CV ${i + 1}: DOCX (extracted ${result.value.length} chars)`);
        } catch (docxError) {
          console.error(`  âŒ CV ${i + 1}: DOCX extraction failed:`, docxError.message);
          parts.push({
            text: '[DOCX extraction failed - unable to analyze this CV]'
          });
        }

      } else if (fileExt === 'pdf') {
        // PDF: Use Gemini File API (supports complex layouts)
        const base64PDF = candidate.cvBuffer.toString('base64');
        parts.push({
          inline_data: {
            mime_type: 'application/pdf',
            data: base64PDF
          }
        });
        console.log(`  ğŸ“„ CV ${i + 1}: PDF (${Math.round(base64PDF.length / 1024)} KB)`);

      } else {
        // Unsupported format - try as text fallback
        console.warn(`  âš ï¸  CV ${i + 1}: Unknown format '${fileExt}', trying as text`);
        const cvText = candidate.cvBuffer.toString('utf-8');
        parts.push({
          text: cvText
        });
      }
    }

    parts.push({
      text: '\n\nPlease analyze ALL CVs above and return a JSON array with one object per CV, in the same order.'
    });

    // Call Gemini API with rate limiting
    const response = await geminiRateLimiter.execute(async () => {
      return await axios.post(
        `${GEMINI_API_URL}?key=${GEMINI_API_KEY}`,
        {
          contents: [{
            parts
          }],
          generationConfig: {
            temperature: 0.4,
            topK: 32,
            topP: 1,
            maxOutputTokens: 8192,
            responseMimeType: 'application/json'
          }
        },
        {
          headers: {
            'Content-Type': 'application/json'
          },
          timeout: 120000 // 2 minutes for batch
        }
      );
    });

    // Parse response
    const responseText = response.data?.candidates?.[0]?.content?.parts?.[0]?.text;

    if (!responseText) {
      throw new Error('Empty response from Gemini API');
    }

    let results;
    try {
      results = JSON.parse(responseText);
    } catch (parseError) {
      console.error('âŒ Gemini JSON Parse Error:', parseError.message);
      console.error('ğŸ“„ Raw Gemini Response:', responseText); // Ham yanÄ±tÄ± logla
      // Gemini'dan gelen yanÄ±tÄ±n neden JSON'a Ã§evrilemediÄŸini anlamak iÃ§in ham yanÄ±tÄ± loglamak Ã§ok Ã¶nemlidir.
      throw new Error('Gemini API\'sinden geÃ§ersiz JSON formatÄ±nda yanÄ±t alÄ±ndÄ±.');
    }

    // Validate we got results for all CVs
    if (!Array.isArray(results) || results.length !== candidatesData.length) {
      console.warn(`âš ï¸  Expected ${candidatesData.length} results, got ${results?.length || 0}`);
    }

    // Map results to candidate IDs
    const mappedResults = results.map((result, index) => ({
      ...result,
      candidateId: candidatesData[index].id,
      fileName: candidatesData[index].fileName
    }));

    console.log(`âœ… Gemini Direct Batch completed: ${mappedResults.length} results`);
    return mappedResults;

  } catch (error) {
    // Axios hatalarÄ±nÄ± daha detaylÄ± loglama
    if (error.response) {
      // API'den bir hata yanÄ±tÄ± geldiyse (Ã¶rn: 4xx, 5xx)
      console.error('âŒ Gemini API Error:', error.response.status, JSON.stringify(error.response.data, null, 2));
    } else if (error.request) {
      // Ä°stek yapÄ±ldÄ± ama yanÄ±t alÄ±namadÄ±ysa (Ã¶rn: aÄŸ hatasÄ±, timeout)
      console.error('âŒ Gemini Network Error:', error.message);
    }
    throw new Error(`Toplu CV analizi baÅŸarÄ±sÄ±z oldu: ${error.message}`);
  }
}

/**
 * Build the master prompt for batch analysis
 */
function buildBatchPrompt(jobPosting, cvCount) {
  return `Sen uzman bir Ä°K yÃ¶neticisisin ve ${cvCount} adet adayÄ±n CV'sini tek bir istekte analiz edeceksin.

Ä°Å Ä°LANI:
Pozisyon: ${jobPosting.title}
Departman: ${jobPosting.department}
Detaylar: ${jobPosting.details}
${jobPosting.notes ? `Notlar: ${jobPosting.notes}` : ''}

GÃ–REVÄ°N:
AÅŸaÄŸÄ±da sana verilen her bir CV iÃ§in, belirtilen formatta bir JSON nesnesi oluÅŸtur. SonuÃ§ olarak, ${cvCount} adet CV iÃ§in ${cvCount} adet nesne iÃ§eren TEK BÄ°R JSON dizisi dÃ¶ndÃ¼rmelisin.

V7.1 Ã‡ERÃ‡EVESÄ° - STRATEJÄ°K DEÄERLENDÄ°RME:

**1. 5 BOYUTLU PUANLAMA (Her boyut 0-100):**
- experienceScore: Ä°ÅŸ deneyimi deÄŸerlendirmesi
- educationScore: EÄŸitim deÄŸerlendirmesi
- technicalScore: Teknik beceriler
- softSkillsScore: Liderlik, iletiÅŸim, problem Ã§Ã¶zme (CV dilinden Ã§Ä±karÄ±m)
- extraScore: Dil, lokasyon, sertifikalar vb.

**2. DÄ°NAMÄ°K AÄIRLIKLANDIRMA:**
Pozisyona gÃ¶re aÄŸÄ±rlÄ±klarÄ± ayarla (toplam 1.0):
AÄŸÄ±rlÄ±klandÄ±rma profilini ÅŸu formatta oluÅŸtur: {
  "experienceWeight": 0.0-0.5,
  "educationWeight": 0.0-0.4,
  "technicalWeight": 0.0-0.4,
  "softSkillsWeight": 0.0-0.3,
  "extraWeight": 0.0-0.2,
  "rationale": "Neden bu aÄŸÄ±rlÄ±klarÄ± seÃ§tin?"
}

**3. KANÄ±T TÄ°PLERÄ°:**
Her yorum iÃ§in kanÄ±t tipini belirt:
- "DoÄŸrudan": CV'de aÃ§Ä±kÃ§a yazan bir bilgi.
- "Ã‡Ä±karÄ±m": CV'deki ifadelerden, projelerden veya kariyer yolculuÄŸundan yapÄ±lan mantÄ±ksal Ã§Ä±karÄ±m.

**4. STRATEJÄ°K Ã–ZET:**
{
  "executiveSummary": "2-3 cÃ¼mlelik yÃ¶netici Ã¶zeti",
  "keyStrengths": ["GÃ¼Ã§lÃ¼ yÃ¶n 1", "GÃ¼Ã§lÃ¼ yÃ¶n 2"],
  "keyRisks": ["Risk 1 (hafifletme Ã¶nerisi ile)"],
  "interviewQuestions": ["Derinlemesine soru 1", "Soru 2"],
  "finalRecommendation": "Ä°lerlet / Beklet / Reddet",
  "hiringTimeline": "Ã–nerilen sonraki adÄ±mlar"
}

**5. KARÄ°YER TRAJEKTÃ–RÃœ:**
AdayÄ±n kariyer bÃ¼yÃ¼me desenini analiz et (terfi, sorumluluk artÄ±ÅŸÄ±, sektÃ¶r deÄŸiÅŸimi).

**ZORUNLU Ã‡IKTI FORMATI:**

  {
    "candidateId": "PLACEHOLDER", // Backend tarafÄ±ndan doldurulacak
    "personalInfo": {
      "firstName": "...",
      "lastName": "...",
      "email": "...",
      "phone": "...",
      "address": "..."
    },
    "scores": {
      "experienceScore": 0-100,
      "educationScore": 0-100,
      "technicalScore": 0-100,
      "softSkillsScore": 0-100,
      "extraScore": 0-100,
      "finalCompatibilityScore": 0-100  // AÄŸÄ±rlÄ±klÄ± ortalama
    },
    "scoringProfile": {
      "experienceWeight": 0.3,
      "educationWeight": 0.25,
      "technicalWeight": 0.25,
      "softSkillsWeight": 0.15,
      "extraWeight": 0.05,
      "rationale": "Junior pozisyon iÃ§in potansiyel ve eÄŸitim Ã¶n planda"
    },
    "analysisSummaries": {
      "experienceSummary": "DetaylÄ± deneyim Ã¶ykÃ¼sÃ¼...",
      "educationSummary": "DetaylÄ± eÄŸitim Ã¶ykÃ¼sÃ¼...",
      "careerTrajectory": "Kariyer bÃ¼yÃ¼me analizi...",
      "positiveComments": [
        "(DoÄŸrudan) 5 yÄ±l React deneyimi var",
        "(Ã‡Ä±karÄ±m) CV'deki proje Ã§eÅŸitliliÄŸinden problem Ã§Ã¶zme yeteneÄŸi gÃ¼Ã§lÃ¼"
      ],
      "negativeComments": [
        "(DoÄŸrudan) Backend deneyimi eksik - Hafifletme: Mikro-servis kursu alabilir"
      ]
    },
    "strategicSummary": {
      "executiveSummary": "...",
      "keyStrengths": ["...", "..."],
      "keyRisks": ["..."],
      "interviewQuestions": ["...", "..."],
      "finalRecommendation": "Ä°lerlet",
      "hiringTimeline": "1 hafta iÃ§inde teknik mÃ¼lakat"
    },
    "matchLabel": "GÃ¼Ã§lÃ¼ EÅŸleÅŸme"
  }
  // ... ${cvCount - 1} adet daha
]

DÄ°KKAT:
- Sadece JSON array dÃ¶ndÃ¼r, baÅŸka metin ekleme!
- ${cvCount} adet object olmalÄ±!
- TÃ¼rkÃ§e karakter encoding doÄŸru olmalÄ± (Ä°, Ä±, ÅŸ, ÄŸ, Ã§, Ã¶, Ã¼)
- Her CV iÃ§in ayrÄ± stratejik deÄŸerlendirme yap!
`;
}

/**
 * Chunk large CV batches into smaller batches to avoid token limits
 * Processes all CVs across multiple API calls
 *
 * @param {string} analysisId - Analysis ID for logging
 * @param {object} jobPosting - Job posting details
 * @param {Array<object>} candidatesData - All candidates data
 * @returns {Promise<Array<object>>} All analysis results combined
 */
async function batchAnalyzeCVsWithChunking(analysisId, jobPosting, candidatesData) {
  const totalCVs = candidatesData.length;

  // If within batch size limit, use direct batch
  if (totalCVs <= BATCH_SIZE) {
    console.log(`ğŸ“¦ Direct batch: ${totalCVs} CVs (within limit)`);
    return await batchAnalyzeCVs(analysisId, jobPosting, candidatesData);
  }

  // Split into chunks
  const chunks = [];
  for (let i = 0; i < totalCVs; i += BATCH_SIZE) {
    chunks.push(candidatesData.slice(i, i + BATCH_SIZE));
  }

  console.log(`ğŸ“¦ Chunking enabled: ${totalCVs} CVs â†’ ${chunks.length} batches (${BATCH_SIZE} per batch)`);

  const allResults = [];
  let processedCount = 0;
  let failedCount = 0;

  // Process each chunk
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];
    const chunkNumber = i + 1;

    try {
      console.log(`â³ Processing batch ${chunkNumber}/${chunks.length} (${chunk.length} CVs)...`);

      const chunkResults = await batchAnalyzeCVs(analysisId, jobPosting, chunk);

      if (chunkResults && Array.isArray(chunkResults)) {
        allResults.push(...chunkResults);
        processedCount += chunkResults.length;
        console.log(`âœ… Batch ${chunkNumber}/${chunks.length} completed: ${chunkResults.length} results`);
      } else {
        failedCount += chunk.length;
        console.error(`âŒ Batch ${chunkNumber}/${chunks.length} returned invalid results`);
      }

    } catch (error) {
      failedCount += chunk.length;
      console.error(`âŒ Batch ${chunkNumber}/${chunks.length} failed:`, error.message);

      // Continue with next batch (partial failure tolerance)
      // Add placeholder results for failed chunk
      for (const candidate of chunk) {
        allResults.push({
          candidateId: candidate.id,
          error: true,
          errorMessage: `Batch ${chunkNumber} failed: ${error.message}`,
          scores: {
            experienceScore: 0,
            educationScore: 0,
            technicalScore: 0,
            softSkillsScore: 0,
            extraScore: 0,
            finalCompatibilityScore: 0
          },
          matchLabel: 'Analiz BaÅŸarÄ±sÄ±z'
        });
      }
    }

    // Delay between batches (except last one)
    if (i < chunks.length - 1) {
      console.log(`â¸ï¸  Waiting ${BATCH_DELAY_MS}ms before next batch...`);
      await new Promise(resolve => setTimeout(resolve, BATCH_DELAY_MS));
    }
  }

  console.log(`ğŸ“Š Chunking summary: ${processedCount} successful, ${failedCount} failed (total ${totalCVs})`);

  if (allResults.length === 0) {
    throw new Error('All batches failed - no results generated');
  }

  return allResults;
}

module.exports = {
  batchAnalyzeCVs,
  batchAnalyzeCVsWithChunking
};
