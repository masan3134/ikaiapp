# Streaming API - DetaylÄ± AÃ§Ä±klama

**Tarih:** 2025-11-02
**Konu:** Gemini API Streaming vs Non-Streaming

---

## ğŸ“– Streaming Nedir?

**Streaming**, API'den gelen yanÄ±tÄ±n **parÃ§a parÃ§a** (chunk by chunk) alÄ±nmasÄ±dÄ±r. TÃ¼m yanÄ±tÄ± beklemek yerine, her kÃ¼Ã§Ã¼k parÃ§a hazÄ±r olduÄŸunda hemen iÅŸlenir.

---

## ğŸ”„ Normal API Call (Non-Streaming)

### **NasÄ±l Ã‡alÄ±ÅŸÄ±r:**

```
Client â†’ Request â†’ API
Client â† .......... â† API (waiting...)
Client â† .......... â† API (waiting...)
Client â† FULL JSON â† API (response complete!)
```

**Kod Ã–rneÄŸi:**
```javascript
// Normal (Non-Streaming) - ÅU ANKÄ° SÄ°STEM
const response = await fetch('https://api.gemini.com/generate', {
  method: 'POST',
  body: JSON.stringify({ prompt: '25 CV analiz et' })
});

const data = await response.json();
console.log(data); // TÃ¼m JSON bir anda geliyor
```

**Timeline:**
```
0s    â†’ Request gÃ¶nderildi
1s    â†’ Gemini dÃ¼ÅŸÃ¼nÃ¼yor...
5s    â†’ Gemini dÃ¼ÅŸÃ¼nÃ¼yor...
10s   â†’ Gemini dÃ¼ÅŸÃ¼nÃ¼yor...
20s   â†’ Gemini dÃ¼ÅŸÃ¼nÃ¼yor...
30s   â†’ âŒ Token limit aÅŸÄ±ldÄ±, JSON kesildi!
```

### **Sorunlar:**

1. **Token Limit AÅŸÄ±mÄ±:**
   - maxOutputTokens = 8192
   - 25 CV analizi ~15,000 token gerektiriyor
   - Response 8192'de kesiliyor â†’ JSON invalid!

2. **Timeout Risk:**
   - Uzun sÃ¼re bekliyor
   - Network timeout (30s-60s)

3. **KullanÄ±cÄ± Deneyimi:**
   - 30 saniye boÅŸ ekran
   - Progress yok
   - BaÅŸarÄ±sÄ±z mÄ± anlayamÄ±yor

---

## ğŸŒŠ Streaming API Call

### **NasÄ±l Ã‡alÄ±ÅŸÄ±r:**

```
Client â†’ Request â†’ API
Client â† CHUNK 1  â† API (first candidate...)
Client â† CHUNK 2  â† API (second candidate...)
Client â† CHUNK 3  â† API (third candidate...)
...
Client â† CHUNK 25 â† API (done!)
```

**Kod Ã–rneÄŸi:**
```javascript
// Streaming - Ã–NERÄ°LEN SÄ°STEM
const response = await fetch('https://api.gemini.com/generate', {
  method: 'POST',
  body: JSON.stringify({
    prompt: '25 CV analiz et',
    stream: true  // â† STREAMING ENABLE
  })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  const chunk = decoder.decode(value);
  console.log('Chunk received:', chunk);

  // Her chunk'Ä± hemen iÅŸle!
  processChunk(chunk);
}
```

**Timeline:**
```
0s    â†’ Request gÃ¶nderildi
2s    â†’ âœ… CHUNK 1: Candidate 1 analizi geldi!
4s    â†’ âœ… CHUNK 2: Candidate 2 analizi geldi!
6s    â†’ âœ… CHUNK 3: Candidate 3 analizi geldi!
...
50s   â†’ âœ… CHUNK 25: TamamlandÄ±!
```

### **Avantajlar:**

1. **Token Limit YOK:**
   - Her chunk ayrÄ± iÅŸleniyor
   - Toplam 1M token bile gelebilir
   - maxOutputTokens sadece chunk size'Ä± sÄ±nÄ±rlÄ±yor

2. **HÄ±zlÄ± Feedback:**
   - Ä°lk sonuÃ§ 2 saniyede
   - KullanÄ±cÄ± hemen gÃ¶rÃ¼yor
   - Progress bar update

3. **Hata ToleransÄ±:**
   - Chunk 15'te hata olsa, ilk 14'Ã¼ kaydedilmiÅŸ
   - Partial success mÃ¼mkÃ¼n

4. **Memory Efficient:**
   - TÃ¼m response bellekte tutulmuyor
   - Her chunk iÅŸlenip garbage collect

---

## ğŸ”§ Teknik Detaylar

### **Gemini API Streaming Format:**

**Request:**
```json
{
  "contents": [{ "parts": [{ "text": "..." }] }],
  "generationConfig": {
    "temperature": 0.4,
    "maxOutputTokens": 8192
  },
  "stream": true
}
```

**Response (SSE - Server-Sent Events):**
```
data: {"candidates":[{"content":{"parts":[{"text":"Candidate 1 analysis..."}]}}]}

data: {"candidates":[{"content":{"parts":[{"text":"Candidate 2 analysis..."}]}}]}

data: {"candidates":[{"content":{"parts":[{"text":"Candidate 3 analysis..."}]}}]}

data: [DONE]
```

### **Node.js Implementation:**

```javascript
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" });

async function streamAnalysis(prompt) {
  const result = await model.generateContentStream(prompt);

  let fullResponse = '';

  for await (const chunk of result.stream) {
    const chunkText = chunk.text();
    fullResponse += chunkText;

    console.log('Chunk:', chunkText);

    // Real-time processing
    emitToClient(chunkText);
  }

  return fullResponse;
}
```

### **Frontend (React) Implementation:**

```typescript
async function startAnalysisWithStreaming(analysisId: string) {
  const response = await fetch(`/api/v1/analyses/${analysisId}/stream`, {
    method: 'GET',
    headers: { Authorization: `Bearer ${token}` }
  });

  const reader = response.body!.getReader();
  const decoder = new TextDecoder();

  let buffer = '';

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });

    // Parse JSON chunks
    const lines = buffer.split('\n');
    buffer = lines.pop() || '';

    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const data = JSON.parse(line.slice(6));

        // Update UI in real-time
        updateAnalysisResult(data);
      }
    }
  }
}
```

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma Tablosu

| Ã–zellik | Normal API | Streaming API |
|---------|-----------|---------------|
| **Token Limit** | 8,192 (hard limit) | Unlimited (per chunk 8K) |
| **Ä°lk SonuÃ§** | 30 saniye | 2-3 saniye |
| **Son SonuÃ§** | 30 saniye | 50 saniye (ama gÃ¶rÃ¼nÃ¼r) |
| **Memory** | TÃ¼m response RAM'de | Chunk by chunk |
| **Hata Durumu** | TÃ¼m data kaybolur | Partial data kaydedilir |
| **UX** | BoÅŸ ekran 30s | Progress bar + sonuÃ§lar |
| **Complexity** | Basit | Orta (async handling) |
| **Retry Logic** | TÃ¼m request tekrar | Sadece failed chunk |

---

## ğŸ¯ IKAI HR Platform Ä°Ã§in Ã–nerilen Mimari

### **Backend (Node.js):**

```javascript
// routes/analysisRoutes.js
router.get('/analyses/:id/stream',
  authenticateToken,
  streamAnalysisResults
);

// controllers/analysisController.js
async function streamAnalysisResults(req, res) {
  const { id } = req.params;

  // Set SSE headers
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');

  try {
    const analysis = await getAnalysis(id);
    const candidates = await getCandidates(analysis.candidateIds);

    // Stream each candidate analysis
    for (const candidate of candidates) {
      const result = await analyzeCandidateStream(candidate, analysis.jobPosting);

      // Send chunk to client
      res.write(`data: ${JSON.stringify(result)}\n\n`);
    }

    res.write('data: [DONE]\n\n');
    res.end();
  } catch (error) {
    res.write(`data: {"error": "${error.message}"}\n\n`);
    res.end();
  }
}
```

### **Frontend (React):**

```typescript
// components/AnalysisStreamViewer.tsx
function AnalysisStreamViewer({ analysisId }: { analysisId: string }) {
  const [results, setResults] = useState<AnalysisResult[]>([]);
  const [progress, setProgress] = useState(0);
  const [total, setTotal] = useState(25);

  useEffect(() => {
    const eventSource = new EventSource(
      `/api/v1/analyses/${analysisId}/stream?token=${getToken()}`
    );

    eventSource.onmessage = (event) => {
      if (event.data === '[DONE]') {
        eventSource.close();
        return;
      }

      const result = JSON.parse(event.data);

      setResults(prev => [...prev, result]);
      setProgress(prev => prev + 1);
    };

    eventSource.onerror = () => {
      eventSource.close();
    };

    return () => eventSource.close();
  }, [analysisId]);

  return (
    <div>
      <ProgressBar value={progress} max={total} />
      {results.map(result => (
        <AnalysisCard key={result.candidateId} data={result} />
      ))}
    </div>
  );
}
```

---

## ğŸš€ Ä°mplementasyon AdÄ±mlarÄ±

### **Phase 1: Backend Streaming (3-4 saat)**

1. âœ… Gemini SDK'yÄ± `generateContentStream` kullanacak ÅŸekilde deÄŸiÅŸtir
2. âœ… SSE endpoint oluÅŸtur (`/analyses/:id/stream`)
3. âœ… Database'e her chunk'Ä± kaydet (partial results)
4. âœ… Error handling (chunk fail â†’ skip, continue)

### **Phase 2: Frontend Integration (2-3 saat)**

1. âœ… EventSource veya fetch + ReadableStream kullan
2. âœ… Real-time UI update (results array'e append)
3. âœ… Progress bar (completed / total)
4. âœ… Error handling (reconnect logic)

### **Phase 3: Testing (1 saat)**

1. âœ… 1 CV test
2. âœ… 10 CV test
3. âœ… 25 CV test
4. âœ… 50 CV test
5. âœ… Network drop test (reconnect)

---

## ğŸ’¡ Alternatif: Quick Fix (Åimdi Yapabiliriz)

**Streaming implement etmeden Ã¶nce:**

### **Option A: Batch Size Reduction**
```javascript
// geminiDirectService.js
const MAX_BATCH_SIZE = 10; // 25 â†’ 10

// 25 CV â†’ 3 batch:
// Batch 1: CV 1-10
// Batch 2: CV 11-20
// Batch 3: CV 21-25
```

**Avantaj:** 5 dakikada uygulanÄ±r
**Dezavantaj:** Streaming kadar iyi deÄŸil

### **Option B: Token Limit Increase**
```javascript
// geminiDirectService.js
maxOutputTokens: 16384 // 8192 â†’ 16K
```

**Avantaj:** 1 dakikada uygulanÄ±r
**Dezavantaj:** Yine de limit var, 40 CV'de patlar

---

## ğŸ¯ Final Recommendation

**SHORT TERM (BugÃ¼n):**
- Batch size 10'a dÃ¼ÅŸÃ¼r
- maxOutputTokens 16K'ya Ã§Ä±k

**LONG TERM (Bu hafta):**
- Streaming implement et
- Batch size 15-20'ye Ã§Ä±k
- maxOutputTokens 8K'da kal (streaming ile gerek yok)

---

## ğŸ“š Kaynaklar

- [Gemini API Streaming Docs](https://ai.google.dev/gemini-api/docs/text-generation?lang=node#generate-a-text-stream)
- [Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
- [Fetch Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API)

---

**SonuÃ§:** Streaming = Netflix'teki progress bar gibi. Video hemen baÅŸlÄ±yor, arka planda indirmeye devam ediyor. AynÄ± mantÄ±k! ğŸ¬
